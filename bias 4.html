<! DOCTYPE html>
<html>
    
    <head>  
        <meta charset="utf-8">
    <link rel="stylesheet" href="styles%20bias%204.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
        <title>bias _ part 4</title>
    </head>
    
<body>
    
    <h1 class="titulo">under-representation bias<br>in search engines</h1>
    
     
    <a class="material-icons" href="início.html">home</a>
    <a href="bias 3.html" class="previous">&laquo; </a>
  
  
    
    <h3>
        
     « Scrubbing to <span
            class="popup-trigger-neutral"><mark>neutral</mark>  <div class="popup-neutral"><p class="texto-1">not saying or doing anything that would encourage or help any of the groups involved in an argument or war.</p></div></span> is basically one of the most common responses that I've seen where people say. "We'll just remove the biased <span
            class="popup-trigger-data"><mark>data</mark>  <div class="popup-data"><p class="texto-2">information, especially facts or numbers, collected to be examined and considered and used to help with making decisions.</p></div></span>, or we'll break the problematic association in say, a word embedding model". But who gets to decide which term should be removed and why those ones in particular? And an even bigger question here is whose idea of neutrality is at work? Do we assume that neutral is what we have in the world today? And if so, how do we account for, in some cases, hundreds of years of discrimination against particular subpopulations? »
        <br> <br>

        « Representational harms often exceed the scope of individual technical interventions. We're basically talking here about how we represent human culture and that requires a different theoretical toolkit. In short, only developing theoretical fixes that come from the technical world for allocated harms is necessary but it's not sufficient. So, we need to consider the bigger issue underlying <span
            class="popup-trigger-fairness"><mark>fairness</mark>  <div class="popup-fairness"><p class="texto-3">the quality of treating people equally or in a way that is right or reasonable.</p></div></span> and bias. »
    </h3>
        
     <h2>Kate Crawford, The Trouble with Bias</h2>
    
    
<h3>
        « We see how contemporary systems use labels to <span
            class="popup-trigger-predict"><mark>predict</mark>  <div class="popup-predict"><p class="texto-4">to say what you think will happen in the future.</p></div></span> human identity, commonly using binary gender, essentialized racial categories, and problematic assessments of character and credit <span
            class="popup-trigger-worthiness"><mark>worthiness</mark>  <div class="popup-worthiness"><p class="texto-5"> the quality of deserving respect or attention.</p></div></span>. » </h3>

       
       <h2>Kate Crawford,  Atlas of AI</h2> 

       <span
            class="popup-trigger-numero-8"><p class="numero-8">(8)</p><div class="popup-numero-8"><img class="imagem-8" src="Ativo 8ldpi.png"></div></span>
        <span
            class="popup-trigger-numero-9"><p class="numero-9">(9)</p><div class="popup-numero-9"><img class="imagem-9" src="ativo 10.png"></div></span>
    
    
    
    </body>
    
</html>